#!/usr/bin/env python

import argparse
import root_gnn
from root_gnn import trainer 
import os

import numpy as np

from graph_nets import utils_tf
import sonnet as snt

from root_gnn import model
from root_gnn.utils import load_yaml
from root_gnn import utils_plot

from root_gnn.trainer import read_dataset
from root_gnn.trainer import loop_dataset
from ROOT import TChain, AddressOf, std

import tensorflow as tf

if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description='Train GNN')
    add_arg = parser.add_argument
    add_arg("-i","--inputfile", help="Path to the input root file")
    add_arg("-o","--outputfile", help="Path of the output root file")
    add_arg("--modeldir", help="Overwrite the model directory from the configuration file", default=None)
    add_arg("--config", help="configuration file name",default=None)

    args = parser.parse_args()
    
    ntuple_in = args.inputfile
    ntuple_out = args.outputfile
    config = load_yaml(args.config)
 
    modeldir = os.path.join(config['output_dir'], 'checkpoints')
    if args.modeldir is not None:
        modeldir = args.modeldir
    
    global_batch_size = config['batch_size']
    num_iters = config['num_iters']      ## level of message-passing
    learning_rate = config['learning_rate']
    # Load the latest checkpoint
    optimizer = snt.optimizers.Adam(learning_rate)
    model = getattr(root_gnn.model, config['model'])()
    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=modeldir, max_to_keep=5)
    if os.path.exists(os.path.join(modeldir, 'checkpoint')):
        status = checkpoint.restore(ckpt_manager.latest_checkpoint)
        print("Loaded latest checkpoint from {}".format(modeldir),status)
    else:
        raise ValueError("Cannot find model at:", modeldir)

    # Apply the model to the jets in the root file
    from root_gnn.datasets import TauIdentificationDataset

    from ROOT import TFile, TTree, TChain, AddressOf, std
    from array import arrayi

    tauid = TauIdentificationDataset()
    tree_name = "output"
    chain = TChain(tree_name,tree_name)
    chain.Add(ntuple_in)
    n_entries = chain.GetEntries()

    # Create a new file and a new branch
    newfile = TFile(ntuple_out,"RECREATE")
    newtree = chain.CloneTree(0)
    leafValues = std.vector('float')()
    newbranch = newtree.Branch("TauPrediction",leafValues)
    
    # Iterate over the entries in the input file
    for ientry in range(n_entries):
        chain.GetEntry(ientry)
        graph_list = tauid.make_graph(chain)
        # Generate graphs and predictions
        leafValues.clear()
        for graph in graph_list:
            outputs = model(graph[0], num_iters,is_training=True)
            #extract gnn output
            output = np.float32(outputs[-1].globals[0][0])
            leafValues.push_back(output)
        newtree.Fill()
    newtree.Write()
