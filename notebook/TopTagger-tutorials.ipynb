{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs as Graphs\n",
    "\n",
    "import itertools\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in Graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"is with shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating graphs from networkx\n",
    "\n",
    "[networkx](https://networkx.org/documentation/stable/tutorial.html) is a Python package for the study of graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "[g.add_node(idx, features=np.array([1.*idx])) for idx in range(4)];\n",
    "\n",
    "# add edges\n",
    "edge_lists = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "[g.add_edge(i, j, features=np.array([abs(i-j)])) for i,j in edge_lists];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "pos = nx.spring_layout(g)\n",
    "nx.draw(g, pos, node_size=400, alpha=0.85, node_color=\"#1f78b4\", with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtain the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = np.asarray(nx.to_numpy_matrix(g))\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (1, 2), (2, 3), (3, 0)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tuple = utils_np.networkxs_to_graphs_tuple([g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphsTuple(nodes=array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]]), edges=array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3]]), receivers=array([1, 2, 3, 0], dtype=int32), senders=array([0, 1, 2, 3], dtype=int32), globals=None, n_node=array([4], dtype=int32), n_edge=array([4], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (4, 1)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "edges is with shape (4, 1)\n",
      "receivers is with shape (4,)\n",
      "[1 2 3 0]\n",
      "senders is with shape (4,)\n",
      "[0 1 2 3]\n",
      "globals EMPTY\n",
      "n_node is with shape (1,)\n",
      "[4]\n",
      "n_edge is with shape (1,)\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GraphsTuple using data-dict \\[recommend\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 4\n",
    "n_node_features = 1\n",
    "n_edge = 4\n",
    "n_edge_features = 1\n",
    "nodes = np.random.rand(n_node, n_node_features).astype(np.float32)\n",
    "edges = np.random.rand(n_edge, n_edge_features).astype(np.float32)\n",
    "receivers = np.array([1, 2, 3, 0])\n",
    "senders = np.array([0, 1, 2, 3])\n",
    "datadict = {\n",
    "    \"n_node\": n_node,\n",
    "    \"n_edge\": n_edge,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"senders\": senders,\n",
    "    \"receivers\": receivers,\n",
    "    \"globals\": np.array([0], dtype=np.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tuple2 = utils_tf.data_dicts_to_graphs_tuple([datadict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (4, 1)\n",
      "tf.Tensor(\n",
      "[[0.859495  ]\n",
      " [0.0219777 ]\n",
      " [0.09030578]\n",
      " [0.4027286 ]], shape=(4, 1), dtype=float32)\n",
      "edges is with shape (4, 1)\n",
      "receivers is with shape (4,)\n",
      "tf.Tensor([1 2 3 0], shape=(4,), dtype=int32)\n",
      "senders is with shape (4,)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
      "globals is with shape (1, 1)\n",
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
      "n_node is with shape (1,)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n",
      "n_edge is with shape (1,)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_tuple2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert an event to a fully-connected graph\n",
    "\n",
    "We take the top tagger dataset as an example: [https://zenodo.org/record/2603256](https://zenodo.org/record/2603256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the directory you saved the data.\n",
    "filename = '/global/homes/x/xju/atlas/data/top-tagger/test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename, mode='r') as store:\n",
    "    df = store['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_0</th>\n",
       "      <th>PX_0</th>\n",
       "      <th>PY_0</th>\n",
       "      <th>PZ_0</th>\n",
       "      <th>E_1</th>\n",
       "      <th>PX_1</th>\n",
       "      <th>PY_1</th>\n",
       "      <th>PZ_1</th>\n",
       "      <th>E_2</th>\n",
       "      <th>PX_2</th>\n",
       "      <th>...</th>\n",
       "      <th>E_199</th>\n",
       "      <th>PX_199</th>\n",
       "      <th>PY_199</th>\n",
       "      <th>PZ_199</th>\n",
       "      <th>truthE</th>\n",
       "      <th>truthPX</th>\n",
       "      <th>truthPY</th>\n",
       "      <th>truthPZ</th>\n",
       "      <th>ttv</th>\n",
       "      <th>is_signal_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>218.364243</td>\n",
       "      <td>-172.341858</td>\n",
       "      <td>110.129105</td>\n",
       "      <td>-76.503624</td>\n",
       "      <td>153.661118</td>\n",
       "      <td>-111.320465</td>\n",
       "      <td>93.167969</td>\n",
       "      <td>-50.390713</td>\n",
       "      <td>76.708054</td>\n",
       "      <td>-56.523701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>122.238762</td>\n",
       "      <td>26.738468</td>\n",
       "      <td>-91.613998</td>\n",
       "      <td>76.382225</td>\n",
       "      <td>121.227135</td>\n",
       "      <td>17.644758</td>\n",
       "      <td>-93.015450</td>\n",
       "      <td>75.715302</td>\n",
       "      <td>90.420105</td>\n",
       "      <td>21.377417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>383.772308</td>\n",
       "      <td>-97.906456</td>\n",
       "      <td>79.640709</td>\n",
       "      <td>-362.426361</td>\n",
       "      <td>200.625992</td>\n",
       "      <td>-54.921326</td>\n",
       "      <td>37.994343</td>\n",
       "      <td>-189.184753</td>\n",
       "      <td>123.247223</td>\n",
       "      <td>-33.828953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>132.492752</td>\n",
       "      <td>-77.763947</td>\n",
       "      <td>-87.322601</td>\n",
       "      <td>-62.304600</td>\n",
       "      <td>83.946594</td>\n",
       "      <td>-49.450481</td>\n",
       "      <td>-53.823605</td>\n",
       "      <td>-41.288010</td>\n",
       "      <td>28.072624</td>\n",
       "      <td>-19.964916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>730.786987</td>\n",
       "      <td>-209.120010</td>\n",
       "      <td>-193.454315</td>\n",
       "      <td>-672.973877</td>\n",
       "      <td>225.477325</td>\n",
       "      <td>-75.363350</td>\n",
       "      <td>-66.226990</td>\n",
       "      <td>-201.926651</td>\n",
       "      <td>217.040192</td>\n",
       "      <td>-63.698189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            E_0        PX_0        PY_0        PZ_0         E_1        PX_1  \\\n",
       "436  218.364243 -172.341858  110.129105  -76.503624  153.661118 -111.320465   \n",
       "440  122.238762   26.738468  -91.613998   76.382225  121.227135   17.644758   \n",
       "441  383.772308  -97.906456   79.640709 -362.426361  200.625992  -54.921326   \n",
       "444  132.492752  -77.763947  -87.322601  -62.304600   83.946594  -49.450481   \n",
       "445  730.786987 -209.120010 -193.454315 -672.973877  225.477325  -75.363350   \n",
       "\n",
       "          PY_1        PZ_1         E_2       PX_2  ...  E_199  PX_199  PY_199  \\\n",
       "436  93.167969  -50.390713   76.708054 -56.523701  ...    0.0     0.0     0.0   \n",
       "440 -93.015450   75.715302   90.420105  21.377417  ...    0.0     0.0     0.0   \n",
       "441  37.994343 -189.184753  123.247223 -33.828953  ...    0.0     0.0     0.0   \n",
       "444 -53.823605  -41.288010   28.072624 -19.964916  ...    0.0     0.0     0.0   \n",
       "445 -66.226990 -201.926651  217.040192 -63.698189  ...    0.0     0.0     0.0   \n",
       "\n",
       "     PZ_199  truthE  truthPX  truthPY  truthPZ  ttv  is_signal_new  \n",
       "436     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "440     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "441     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "444     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "445     0.0     0.0      0.0      0.0      0.0    1              0  \n",
       "\n",
       "[5 rows x 806 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E_0              218.364243\n",
       "PX_0            -172.341858\n",
       "PY_0             110.129105\n",
       "PZ_0             -76.503624\n",
       "E_1              153.661118\n",
       "                    ...    \n",
       "truthPX            0.000000\n",
       "truthPY            0.000000\n",
       "truthPZ            0.000000\n",
       "ttv                1.000000\n",
       "is_signal_new      0.000000\n",
       "Name: 436, Length: 806, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = df.iloc[0]\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['E', 'PX', 'PY', 'PZ']\n",
    "scale = 0.001\n",
    "solution = 'is_signal_new'\n",
    "\n",
    "def make_graph(event, debug: Optional[bool] = False):\n",
    "    n_max_nodes = 200\n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    for inode in range(n_max_nodes):\n",
    "        E_name = 'E_{}'.format(inode)\n",
    "        if event[E_name] < 0.1:\n",
    "            continue\n",
    "\n",
    "        f_keynames = ['{}_{}'.format(x, inode) for x in features]\n",
    "        n_nodes += 1\n",
    "        nodes.append(event[f_keynames].values*scale)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "\n",
    "    # to make a bi-directional fully connected graph\n",
    "    all_edges = list(itertools.combinations(range(n_nodes), 2))\n",
    "    senders = np.array([x[0] for x in all_edges])\n",
    "    receivers = np.array([x[1] for x in all_edges])\n",
    "    n_edges = len(all_edges)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    return [(input_graph, target_graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = make_graph(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_evt_input, g_evt_target = graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes is with shape (17, 4)\n",
      "edges is with shape (136, 1)\n",
      "receivers is with shape (136,)\n",
      "senders is with shape (136,)\n",
      "globals is with shape (1, 1)\n",
      "n_node is with shape (1,)\n",
      "n_edge is with shape (1,)\n"
     ]
    }
   ],
   "source": [
    "print_graphs_tuple(g_evt_input, data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17*16//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_evt_target.globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all events into graphs and save these graphs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    with pd.HDFStore(filename, mode='r') as store:\n",
    "        df = store['table']\n",
    "\n",
    "    for ievt in range(df.shape[0]):\n",
    "        yield df.iloc[ievt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from root_gnn.src.datasets.base import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopTaggerDataset(DataSet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.read = read\n",
    "        self.make_graph = make_graph\n",
    "\n",
    "    def _num_evts(self, filename):\n",
    "        with pd.HDFStore(filename, mode='r') as store:\n",
    "            df = store['table']\n",
    "        return df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TopTaggerDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_filename = '/global/homes/x/xju/atlas/data/top-tagger/train.h5'\n",
    "n_evts_per_record = 10\n",
    "debug = False\n",
    "max_evts = 100\n",
    "num_workers = 1\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 100 events are requested to be written to 10 files with 1 workers\n",
      "TopTaggerDataset added 100 events, in 4.6 mins\n",
      "0 events failed in being converted to graph\n"
     ]
    }
   ],
   "source": [
    "# using multiprocessing in jupyter notebook seems problematic..\n",
    "# It is a slow process. Suggest adding the new DataSet class to root_gnn.dataset\n",
    "# and use the `create_tfrecord` script to process the events\n",
    "\n",
    "data.process(filename=tr_filename, outname=\"TopTagger/trainning\",\\\n",
    "    n_evts_per_record=n_evts_per_record, debug=debug,\n",
    "    max_evts=max_evts, num_workers=num_workers, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning_0.tfrec  trainning_3.tfrec  trainning_6.tfrec  trainning_9.tfrec\n",
      "trainning_1.tfrec  trainning_4.tfrec  trainning_7.tfrec\n",
      "trainning_2.tfrec  trainning_5.tfrec  trainning_8.tfrec\n"
     ]
    }
   ],
   "source": [
    "!ls TopTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-06 23:17:05.049322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Shuffling input files\n",
      "Total 10 files\n",
      "Training   8 files\n",
      "Validation 1 files\n",
      "Testing    1 files\n"
     ]
    }
   ],
   "source": [
    "!split_files_for_nn TopTagger inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  val\n"
     ]
    }
   ],
   "source": [
    "!ls inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TF Version:2.4.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs as Graphs\n",
    "import sonnet as snt\n",
    "\n",
    "import itertools\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "from root_gnn import model as Models\n",
    "from root_gnn import losses\n",
    "from root_gnn.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module root_gnn.model in root_gnn:\n",
      "\n",
      "NAME\n",
      "    root_gnn.model\n",
      "\n",
      "DESCRIPTION\n",
      "    The implementation of Graph Networks are mostly inspired by the ones in deepmind/graphs_nets\n",
      "    https://github.com/deepmind/graph_nets\n",
      "\n",
      "CLASSES\n",
      "    root_gnn.src.models.edge_learner.EdgeLearnerBase(sonnet.src.base.Module)\n",
      "        root_gnn.src.models.edge_learner.EdgeClassifier\n",
      "        root_gnn.src.models.edge_learner.EdgeRegression\n",
      "    root_gnn.src.models.global_learner.GlobalLearnerBase(sonnet.src.base.Module)\n",
      "        root_gnn.src.models.global_learner.GlobalClassifier\n",
      "        root_gnn.src.models.global_learner.GlobalRegression\n",
      "    \n",
      "    class EdgeClassifier(EdgeLearnerBase)\n",
      "     |  EdgeClassifier(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EdgeClassifier\n",
      "     |      EdgeLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, with_edge_inputs=False, with_node_inputs=True, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='EdgeClassifier', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from EdgeLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class EdgeRegression(EdgeLearnerBase)\n",
      "     |  EdgeRegression(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EdgeRegression\n",
      "     |      EdgeLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, edge_output_size, with_edge_inputs=False, with_node_inputs=True, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='EdgeRegression', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from EdgeLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GlobalClassifier(GlobalLearnerBase)\n",
      "     |  GlobalClassifier(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlobalClassifier\n",
      "     |      GlobalLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalClassifier', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GlobalLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GlobalRegression(GlobalLearnerBase)\n",
      "     |  GlobalRegression(*args, **kwargs) -> ~T\n",
      "     |  \n",
      "     |  Base class for Sonnet modules.\n",
      "     |  \n",
      "     |  A Sonnet module is a lightweight container for variables and other modules.\n",
      "     |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      "     |  which apply operations combining user input and module parameters. For\n",
      "     |  example::\n",
      "     |  \n",
      "     |      >>> class MultiplyModule(snt.Module):\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(2., name='w')\n",
      "     |      ...     return x * self.w\n",
      "     |  \n",
      "     |      >>> mod = MultiplyModule()\n",
      "     |      >>> mod(1.)\n",
      "     |      <tf.Tensor: ... numpy=2.0>\n",
      "     |  \n",
      "     |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      "     |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlobalRegression\n",
      "     |      GlobalLearnerBase\n",
      "     |      sonnet.src.base.Module\n",
      "     |      tensorflow.python.module.module.Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, global_output_size, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalRegression', **kwargs)\n",
      "     |      Initializes the current module with the given name.\n",
      "     |      \n",
      "     |      Subclasses should call this constructor before creating other modules or\n",
      "     |      variables such that those modules are named correctly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: An optional string name for the class. Must be a valid Python\n",
      "     |          identifier. If ``name`` is not provided then the class name for the\n",
      "     |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      "     |  \n",
      "     |  __repr__ lambda module\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GlobalLearnerBase:\n",
      "     |  \n",
      "     |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sonnet.src.base.Module:\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.trainable_variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      See :tf:`Module.variables` for implementation details.\n",
      "     |      \n",
      "     |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      "     |      are called). As such just after construction there are typically no\n",
      "     |      variables. To mitigate a common error (calling ``.variables`` or\n",
      "     |      ``.trainable_variables`` before any variables are created) these properties\n",
      "     |      will raise an exception if their result is empty. See\n",
      "     |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ('EdgeClassifier', 'EdgeRegression', 'GlobalClassifier', 'Gl...\n",
      "\n",
      "FILE\n",
      "    /global/cfs/cdirs/atlas/xju/testarea/root_gnn/root_gnn/model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GlobalRegression in module root_gnn.src.models.global_learner:\n",
      "\n",
      "class GlobalRegression(GlobalLearnerBase)\n",
      " |  GlobalRegression(*args, **kwargs) -> ~T\n",
      " |  \n",
      " |  Base class for Sonnet modules.\n",
      " |  \n",
      " |  A Sonnet module is a lightweight container for variables and other modules.\n",
      " |  Modules typically define one or more \"forward\" methods (e.g. ``__call__``)\n",
      " |  which apply operations combining user input and module parameters. For\n",
      " |  example::\n",
      " |  \n",
      " |      >>> class MultiplyModule(snt.Module):\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(2., name='w')\n",
      " |      ...     return x * self.w\n",
      " |  \n",
      " |      >>> mod = MultiplyModule()\n",
      " |      >>> mod(1.)\n",
      " |      <tf.Tensor: ... numpy=2.0>\n",
      " |  \n",
      " |  Sonnet modules are a layer on top of :tf:`Module`, implementing automatic name\n",
      " |  scoping as described in the original RFC :cite:`agarwal2019stateful`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GlobalRegression\n",
      " |      GlobalLearnerBase\n",
      " |      sonnet.src.base.Module\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, global_output_size, with_edge_inputs=False, with_node_inputs=True, with_global_inputs=False, encoder_size: list = None, core_size: list = None, decoder_size: list = None, name='GlobalRegression', **kwargs)\n",
      " |      Initializes the current module with the given name.\n",
      " |      \n",
      " |      Subclasses should call this constructor before creating other modules or\n",
      " |      variables such that those modules are named correctly.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: An optional string name for the class. Must be a valid Python\n",
      " |          identifier. If ``name`` is not provided then the class name for the\n",
      " |          current instance is converted to ``lower_snake_case`` and used instead.\n",
      " |  \n",
      " |  __repr__ lambda module\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from GlobalLearnerBase:\n",
      " |  \n",
      " |  __call__(self, input_op, num_processing_steps, is_training=True)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sonnet.src.base.Module:\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      " |      \n",
      " |      See :tf:`Module.trainable_variables` for implementation details.\n",
      " |      \n",
      " |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      " |      are called). As such just after construction there are typically no\n",
      " |      variables. To mitigate a common error (calling ``.variables`` or\n",
      " |      ``.trainable_variables`` before any variables are created) these properties\n",
      " |      will raise an exception if their result is empty. See\n",
      " |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  variables\n",
      " |      Sequence of :tf:`Variable`\\ s owned by this module and it's submodules.\n",
      " |      \n",
      " |      See :tf:`Module.variables` for implementation details.\n",
      " |      \n",
      " |      NOTE: Most Sonnet modules create variables lazily (e.g. the first time they\n",
      " |      are called). As such just after construction there are typically no\n",
      " |      variables. To mitigate a common error (calling ``.variables`` or\n",
      " |      ``.trainable_variables`` before any variables are created) these properties\n",
      " |      will raise an exception if their result is empty. See\n",
      " |      :func:`allow_empty_variables` if you want to suppress this error.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from sonnet.src.base.ModuleMetaclass\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Models.GlobalRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Models.GlobalClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = losses.GlobalLoss(real_global_weight=1., fake_global_weight=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "optimizer = snt.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning_1.tfrec  trainning_4.tfrec  trainning_6.tfrec  trainning_8.tfrec\n",
      "trainning_3.tfrec  trainning_5.tfrec  trainning_7.tfrec  trainning_9.tfrec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls inputs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode, -> 'rgr,globals', ['clf', 'rgr'], ['globals', 'edges']\n",
    "trainer = Trainer(input_dir=\"inputs\", output_dir=\"TrainedResults\",\n",
    "                  model=model, loss_fcn=loss_fcn, optimizer=optimizer,\n",
    "                  evts_per_file=n_evts_per_record, mode='clf,globals', batch_size=10,\n",
    "                  val_batches=10, log_freq=10, patiences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts with 80 graphs with batch size of 10 for 1 epochs\n",
      "runing 100 steps, 8 steps per epoch, and stop on variable val_loss\n",
      "Tracing update_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifier/edge_encoder_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:18<31:05, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>446,081 trainable parameters<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 10/100 [00:22<00:56,  1.60it/s]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 10%|â–ˆ         | 10/100 [00:25<00:56,  1.60it/s, acc=1, auc=nan, loss=1.28, pre=0, rec=0, val_loss=0.575]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading latest checkpoint from: TrainedResults/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 20/100 [00:29<00:40,  2.00it/s, acc=1, auc=nan, loss=1.28, pre=0, rec=0, val_loss=0.575]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:36<00:30,  2.28it/s, acc=0, auc=nan, loss=0.754, pre=0, rec=0, val_loss=0.754]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:43<00:27,  2.20it/s, acc=0.2, auc=nan, loss=0.698, pre=0, rec=0, val_loss=0.715]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:48<00:17,  2.78it/s, acc=0.3, auc=nan, loss=0.688, pre=0, rec=0, val_loss=0.675]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [00:54<00:15,  2.52it/s, acc=0.7, auc=nan, loss=0.687, pre=0, rec=0, val_loss=0.616]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:00<00:12,  2.47it/s, acc=0.6, auc=nan, loss=0.648, pre=0, rec=0, val_loss=0.605]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:05<00:08,  2.49it/s, acc=0.4, auc=nan, loss=0.64, pre=0, rec=0, val_loss=0.68]  /global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [01:11<00:03,  2.90it/s, acc=0.4, auc=nan, loss=0.598, pre=0, rec=0, val_loss=0.641]/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/global/homes/x/xju/.conda/envs/tf2.4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:17<00:00,  1.30it/s, acc=0.4, auc=nan, loss=0.621, pre=0, rec=0, val_loss=0.608]\n"
     ]
    }
   ],
   "source": [
    "## training for 100 batches\n",
    "trainer.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-TF2.4",
   "language": "python",
   "name": "tf2p4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
